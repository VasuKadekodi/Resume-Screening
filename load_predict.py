# -*- coding: utf-8 -*-
"""Load_Predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1agQ2Hz3-oKtUYg43B22kFIeBU0vQBzR8
"""

from google.colab import drive
drive.mount('/content/drive')

# To extract text, images, and metadata from PDF documents
!pip install pdfminer
!pip install pdfminer3
!pip install pdfminer.six

from pdfminer.high_level import extract_text

# Extracting text from pdf file
text = extract_text('/content/drive/MyDrive/Vasundhara_Kadekodi.pdf')

# Replace new line characters with spaces
text=text.replace('\n', '')

# Replacing multiple spaces with sigle space
text=' '.join(text.split())

import re
import string

punctuations = string.punctuation

# Convering all string to lowecase
text=text.lower()

# removing numbers
text=re.sub('r\d+','',text)

# Removing punctuation
text=text.translate(str.maketrans('','',string.punctuation))

"""## **Loading the Model**"""

import pickle
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

# Loading pre-trained model and vectorizer
with open('/content/drive/MyDrive/Projects/Resume Screening/model_Pred.pkl', 'rb') as f:
  model= pickle.load(f)

with open('/content/drive/MyDrive/Projects/Resume Screening/vectorizer_Pred.pkl', 'rb') as f:
  vectorizer = pickle.load(f)

text

# transforming text file
X = vectorizer.transform([text])

# Predictions
y_pred = model.predict(X)
print("Predicted class:", y_pred[0])

# probability estimates
y_prob = model.predict_proba(X)
print('Predicted class:', y_pred[0], '\n', 'Class Probability:', y_prob[0][y_pred[0]])

# Create dictionary with industrial and system engineering key terms by area
terms = {'Quality/Six Sigma':['black belt','capability analysis','control charts','doe','dmaic','fishbone',
                              'gage r&r', 'green belt','ishikawa','iso','kaizen','kpi','lean','metrics',
                              'pdsa','performance improvement','process improvement','quality',
                              'quality circles','quality tools','root cause','six sigma',
                              'stability analysis','statistical analysis','tqm'],      
        'Operations management':['automation','bottleneck','constraints','cycle time','efficiency','fmea',
                                 'machinery','maintenance','manufacture','line balancing','oee','operations',
                                 'operations research','optimization','overall equipment effectiveness',
                                 'pfmea','process','process mapping','production','resources','safety',
                                 'stoppage','value stream mapping','utilization'],
        'Supply chain':['abc analysis','apics','customer','customs','delivery','distribution','eoq','epq',
                        'fleet','forecast','inventory','logistic','materials','outsourcing','procurement',
                        'reorder point','rout','safety stock','scheduling','shipping','stock','suppliers',
                        'third party logistics','transport','transportation','traffic','supply chain',
                        'vendor','warehouse','wip','work in progress'],
        'Project management':['administration','agile','budget','cost','direction','feasibility analysis',
                              'finance','kanban','leader','leadership','management','milestones','planning',
                              'pmi','pmp','problem','project','risk','schedule','scrum','stakeholders'],
        'Data analytics':['analytics','api','aws','big data','busines intelligence','clustering','code',
                          'coding','data','database','data mining','data science','deep learning','hadoop',
                          'hypothesis test','iot','internet','machine learning','modeling','nosql','nlp',
                          'predictive','programming','python','r','sql','tableau','text mining',
                          'visualuzation'],
        'Healthcare':['adverse events','care','clinic','cphq','ergonomics','healthcare',
                      'health care','health','hospital','human factors','medical','near misses',
                      'patient','reporting system']}

"""### Scores calculation per area"""

# Initializie score counters for each area
quality = 0
operations = 0
supplychain = 0
project = 0
data = 0
healthcare = 0

# Create an empty list where the scores will be stored
scores = []

# Obtain the scores for each area
for area in terms.keys():
        
    if area == 'Quality/Six Sigma':
        for word in terms[area]:
            if word in text:
                quality +=1
        scores.append(quality)
        
    elif area == 'Operations management':
        for word in terms[area]:
            if word in text:
                operations +=1
        scores.append(operations)
        
    elif area == 'Supply chain':
        for word in terms[area]:
            if word in text:
                supplychain +=1
        scores.append(supplychain)
        
    elif area == 'Project management':
        for word in terms[area]:
            if word in text:
                project +=1
        scores.append(project)
        
    elif area == 'Data analytics':
        for word in terms[area]:
            if word in text:
                data +=1
        scores.append(data)
        
    else:
        for word in terms[area]:
            if word in text:
                healthcare +=1
        scores.append(healthcare)

"""### Scores Summary"""

import pandas as pd
# Create a data frame with the scores summary
summary = pd.DataFrame(scores,index=terms.keys(),columns=['score']).sort_values(by='score',ascending=False)
summary

"""### Visualizing skills score using pie char to a related fields"""

import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
import seaborn as sns

# Create pie chart visualization
pie = plt.figure(figsize=(5,5))
# the_grid=GridSpec(2,2)
wedgeprops = {'linewidth': 2, 'edgecolor': 'white'}

plt.pie(summary['score'], labels=summary.index, colors=sns.color_palette('cool') ,  autopct='%1.0f%%',shadow=True, wedgeprops=wedgeprops)
plt.title('Industrial Engineering Candidate - Resume Decomposition by Areas')
plt.axis('equal')
plt.show()

# Save pie chart as a .png file
pie.savefig('resume_screening_results.png')

